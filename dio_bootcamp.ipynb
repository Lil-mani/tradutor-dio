{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests python-docx"
      ],
      "metadata": {
        "id": "-ITkYenKEdip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e779aa9-785f-4d2d-e875-c149b2f0ce35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from docx import Document\n",
        "import os\n",
        "\n",
        "subscription_key = \"\"\n",
        "# https://api.cognitive.microsofttranslator.com/\n",
        "endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
        "location = \"westus2\"\n",
        "path = '/translate'\n",
        "target_lang = \"pt-br\"\n",
        "\n",
        "# Como default vamos deixar o portugues como linguagem alvo\n",
        "# e vamos definir o conteúdo enviado ao servidor por meio do\n",
        "# protocolo HTTP para utilizar a API de tradução\n",
        "def translator_text(text,target_language = \"pt-br\"):\n",
        "  path = '/translate'\n",
        "  constructed_url = endpoint + path\n",
        "  # Headers: esse dicionario especifica cabeçalhos HTTP para a solicitação\n",
        "  headers = {\n",
        "      # chave de autenticação da solicitação\n",
        "      'Ocp-Apim-Subscription-Key': subscription_key,\n",
        "      # região associada a chave\n",
        "      'Ocp-Apim-Subscription-Region': location,\n",
        "      # definir que o formato da solicitação será em JSON\n",
        "      'Content-type': 'application/json',\n",
        "      # identificador para rastrear solicitação\n",
        "      'X-ClientTraceId': str(os.urandom(16))\n",
        "      }\n",
        "  # corpo da requisição, aqui vai estar o conteudo que vai ser traduzido\n",
        "  body = [{\n",
        "      'text': text\n",
        "  }]\n",
        "\n",
        "  params = {\n",
        "      'api-version': '3.0',\n",
        "      'from': 'en',\n",
        "      'to': target_language\n",
        "  }\n",
        "  # Vamos retornar um json com o texto traduzido\n",
        "  request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
        "  response = request.json()\n",
        "  return response[0][\"translations\"][0][\"text\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5xYwzR6aY80_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "f5a0f8a2-5c1f-4c92-874e-11461bf55737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'docx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0c3e4b285b4a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubscription_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator_text(\"I know you're somewhere out there, somewhere far away\",target_lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O2uiSY8gch6w",
        "outputId": "0c0d5b30-bf86-4a12-996a-cf9fd5db3ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eu sei que você está em algum lugar lá fora, em algum lugar distante'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_doc(path):\n",
        "  document = Document(path)\n",
        "  full_text = []\n",
        "\n",
        "\n",
        "  for paragraph in document.paragraphs:\n",
        "    full_text.append(translator_text(paragraph.text,target_lang))\n",
        "\n",
        "\n",
        "  translated_doc = Document()\n",
        "  for line in full_text:\n",
        "    translated_doc.add_paragraph(line)\n",
        "\n",
        "  path_translated = path.replace(\".docx\",f\"_{target_lang}.docx\")\n",
        "  translated_doc.save(path_translated)\n",
        "\n",
        "\n",
        "  return path_translated\n",
        "\n",
        "# input_file = \"/content/musica.pdf\"\n",
        "# translate_doc(input_file)\n"
      ],
      "metadata": {
        "id": "_VjpG4oMcjEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 openai langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpJXtuNUgWrO",
        "outputId": "4de7a9fa-0cbe-4b76-d488-e17e94de8912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting openai\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting langchain-core<0.4.0,>=0.3.13 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.13-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain-openai) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.13->langchain-openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.13->langchain-openai)\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain-openai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.13->langchain-openai)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.13->langchain-openai)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.13->langchain-openai)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.13-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson, jsonpointer, jiter, h11, tiktoken, requests-toolbelt, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.13 langchain-openai-0.2.4 langsmith-0.1.137 openai-1.52.2 orjson-3.10.10 requests-toolbelt-1.0.0 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usar o chat da openai para fazer a tradução de pagina da web"
      ],
      "metadata": {
        "id": "vJjwwSAgmqW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "# from langchain.llms import OpenAI\n",
        "\n",
        "def extract_text_url(url):\n",
        "    response = requests.get(url)\n",
        "    #status 200 http é resposta de status de sucesso de requisição\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Erro ao acessar a URL: {url}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    for script_or_style in soup(['script','style']):\n",
        "        script_or_style.decompose()\n",
        "\n",
        "    text = soup.get_text(separator=' ')\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    clean_text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "    return clean_text\n",
        "\n",
        "\n",
        "extract_text_url(\"https://medium.com/@ignacio.de.gregorio.noblejas/has-google-leaked-openais-secret-d5619f05eccf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lKvVTGY7g3Zd",
        "outputId": "1b27331e-5e13-4cbc-8d8e-a1000da6d011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Has Google Leaked OpenAI’s Secret? | Medium Open in app Sign up Sign in Write Sign up Sign in Member-only story Has Google Leaked OpenAI’s Secret? The Secret to Self-Correction Ignacio de Gregorio · Follow 8 min read · Oct 7, 2024 -- 9 Share Source: Generated by author using GPT-4o Google has presented self-correcting LLMs via Reinforcement Learning (SCoRE),\\na new method that teaches models to acknowledge and correct their own mistakes (in case you’re wondering, LLMs are terrible at it). This opens a new world of possibilities for AI that is smarter and more ‘self-aware.’ Interestingly, OpenAI’s o1 models excel at this particular capability, which might have been the key to their superior performance. Now, Google could have just spilled the beans on a crucial process step. Understanding this research will give you great insight into how AI models learn, how we tune the learning objective to our advantage, and how frontier labs train the next generation of AI models. Let’s dive in. This article is an extract from my newsletter, the place where AI analysts, strategists, and decision-makers use to find answers to the most pressing questions in AI. TheTechOasis The newsletter to stay ahead of the curve in AI thetechoasis.beehiiv.com The Importance of Self-Correction -- -- 9 Follow Written by\\nIgnacio de Gregorio 162K Followers I break down AI in easy-to-understand language for you. Sign up here:\\nhttps://thetechoasis.beehiiv.com/subscribe\\nBusiness inquiries:\\nnacho@thewhitebox.ai Follow Help Status About Careers Press Blog Privacy Terms Text to speech Teams'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import AzureChatOpenAI\n",
        "\n",
        "client = AzureChatOpenAI(\n",
        "    azure_endpoint=\"https://oai-dio-bootcamp-dev-eastus-01.openai.azure.com/\",\n",
        "    api_key = \"\",\n",
        "    api_version=\"2024-02-15-preview\",\n",
        "    deployment_name=\"gpt-4o-mini\",\n",
        "    max_retries=0,\n",
        ")\n",
        "\n",
        "\n",
        "def translate_article(text,lang):\n",
        "  messages= [\n",
        "      (\"system\",\"Você atua como tradutor\"),\n",
        "      (\"user\", f\"Traduza o {text} para o idioma {lang} e responda markdown\")\n",
        "  ]\n",
        "\n",
        "\n",
        "  response = client.invoke(messages)\n",
        "  print(response.content)\n",
        "  return response.content\n",
        "\n",
        "translate_article(\"Let's see if this works!\",\"portugues\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yhN8-3QhisAZ",
        "outputId": "68626fed-c760-4aea-966f-ef9f688d7d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vamos ver se isso funciona!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Vamos ver se isso funciona!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://dev.to/emmanuelkadominah/hello-world-430b\"\n",
        "text = extract_text_url(url)\n",
        "print(text[:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDCE1KZhmwhb",
        "outputId": "279e3a16-063f-4d94-d1cc-68d56874e0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World! - DEV Community\n",
            "Skip to content\n",
            "Navigation menu\n",
            "Search\n",
            "Powered by\n",
            "Search\n",
            "Algolia\n",
            "Search\n",
            "Log in\n",
            "Create account\n",
            "DEV Community\n",
            "Close\n",
            "Add reaction\n",
            "Like\n",
            "Unicorn\n",
            "Exploding Head\n",
            "Raised Hands\n",
            "Fire\n",
            "Jump to Comments\n",
            "Save\n",
            "More...\n",
            "Copy link\n",
            "Copy link\n",
            "Copied to Clipboard\n",
            "Share to Twitter\n",
            "Share to LinkedIn\n",
            "Share to Reddit\n",
            "Share to Hacker News\n",
            "Share to Facebook\n",
            "Share to Mastodon\n",
            "Report Abuse\n",
            "emmanuel-k-adominah\n",
            "Posted on\n",
            "Feb 22, 2022\n",
            "Hello World!\n",
            "# react\n",
            "# python\n",
            "# devops\n",
            "# node\n",
            "Simple way of writing programming...\n",
            "Top comments\n",
            "(0)\n",
            "Subscribe\n",
            "Personal\n",
            "Trusted User\n",
            "Create template\n",
            "Templates let you quickly answer FAQs or store snippets for re-use.\n",
            "Submit\n",
            "Preview\n",
            "Dismiss\n",
            "Code of Conduct\n",
            "•\n",
            "Report abuse\n",
            "Are you sure you want to hide this comment? It will become hidden in your post, but will still\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate_article(text[:400],\"portugues\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "wbOk6PfvoR9T",
        "outputId": "37beb5c5-0e21-4ee5-cff2-a161b0937d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Claro! Aqui está a tradução para o português do seu texto em Markdown:\n",
            "\n",
            "```markdown\n",
            "# Olá, Mundo! - Comunidade DEV\n",
            "Pule para o conteúdo\n",
            "Menu de navegação\n",
            "Buscar\n",
            "Powered by\n",
            "Buscar\n",
            "Algolia\n",
            "Buscar\n",
            "Entrar\n",
            "Criar conta\n",
            "Comunidade DEV\n",
            "Fechar\n",
            "Adicionar reação\n",
            "Curtir\n",
            "Unicórnio\n",
            "Cabeça Explodindo\n",
            "Mãos Erguidas\n",
            "Fogo\n",
            "Pular para Comentários\n",
            "Salvar\n",
            "Mais...\n",
            "Copiar link\n",
            "Copiar link\n",
            "Copiado para a área de transferência\n",
            "Compartilhar no Twitter\n",
            "Compartilhar no LinkedIn\n",
            "Compartilhar no Reddit\n",
            "Compartilhar no Hacker News\n",
            "Compartilhar no Facebook\n",
            "Compartilhar no Mastodon\n",
            "Reportar Abuso\n",
            "```\n",
            "\n",
            "Se precisar de mais alguma coisa, é só avisar!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Claro! Aqui está a tradução para o português do seu texto em Markdown:\\n\\n```markdown\\n# Olá, Mundo! - Comunidade DEV\\nPule para o conteúdo\\nMenu de navegação\\nBuscar\\nPowered by\\nBuscar\\nAlgolia\\nBuscar\\nEntrar\\nCriar conta\\nComunidade DEV\\nFechar\\nAdicionar reação\\nCurtir\\nUnicórnio\\nCabeça Explodindo\\nMãos Erguidas\\nFogo\\nPular para Comentários\\nSalvar\\nMais...\\nCopiar link\\nCopiar link\\nCopiado para a área de transferência\\nCompartilhar no Twitter\\nCompartilhar no LinkedIn\\nCompartilhar no Reddit\\nCompartilhar no Hacker News\\nCompartilhar no Facebook\\nCompartilhar no Mastodon\\nReportar Abuso\\n```\\n\\nSe precisar de mais alguma coisa, é só avisar!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}